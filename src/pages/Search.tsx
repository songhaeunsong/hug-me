import { useRef, useState } from 'react';

import { usePostSpeech } from '@/api/stt';

export const Search = () => {
  const postSpeech = usePostSpeech();
  const [recording, setRecording] = useState(false);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const silenceTimerRef = useRef<ReturnType<typeof setTimeout> | null>(null);

  const startRecording = async () => {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    const recorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
    let chunks: Blob[] = [];

    // ğŸ”Š AudioContextë¡œ ìŒì„± í¬ê¸° ì¸¡ì •
    const audioContext = new AudioContext();
    const source = audioContext.createMediaStreamSource(stream);
    const analyser = audioContext.createAnalyser();
    source.connect(analyser);

    const dataArray = new Uint8Array(analyser.fftSize);

    const checkSilence = () => {
      analyser.getByteTimeDomainData(dataArray);

      // íŒŒí˜• ì¤‘ì•™(128)ì—ì„œ ì–¼ë§ˆë‚˜ ë²—ì–´ë‚¬ëŠ”ì§€ ì¸¡ì • â†’ ì‘ìœ¼ë©´ ë¬´ìŒ
      const volume = dataArray.reduce((acc, val) => acc + Math.abs(val - 128), 0) / dataArray.length;

      if (volume < 2) {
        // ë¬´ìŒ êµ¬ê°„ ì‹œì‘
        if (!silenceTimerRef.current) {
          silenceTimerRef.current = setTimeout(() => {
            stopRecording();
          }, 5000);
        }
      } else {
        // ë‹¤ì‹œ ì†Œë¦¬ ê°ì§€ â†’ íƒ€ì´ë¨¸ ì´ˆê¸°í™”
        if (silenceTimerRef.current) {
          clearTimeout(silenceTimerRef.current);
          silenceTimerRef.current = null;
        }
      }

      if (recording) requestAnimationFrame(checkSilence);
    };

    recorder.ondataavailable = (e) => {
      if (e.data.size > 0) chunks.push(e.data);
    };

    recorder.onstop = () => {
      const audioBlob = new Blob(chunks, { type: 'audio/webm' });
      chunks = [];

      // ì„œë²„ì— ì „ì†¡
      sendToServer(audioBlob);
    };

    recorder.start();
    mediaRecorderRef.current = recorder;
    setRecording(true);
    checkSilence();
  };

  const sendToServer = async (blob: Blob) => {
    const formData = new FormData();
    formData.append('file', blob, 'recording.webm');

    postSpeech(formData, {
      onSuccess: (data) => {
        console.log('here', data);
      },
    });
  };

  const stopRecording = () => {
    if (mediaRecorderRef.current) {
      mediaRecorderRef.current.stop();
      setRecording(false);
    }
    if (silenceTimerRef.current) {
      clearTimeout(silenceTimerRef.current);
      silenceTimerRef.current = null;
    }
  };

  return (
    <div style={{ padding: '20px' }}>
      <h2>ğŸ¤ ìë™ ì œì¶œ ë…¹ìŒê¸°</h2>
      <button onClick={recording ? stopRecording : startRecording}>{recording ? 'â¹ ìˆ˜ë™ ì¤‘ì§€' : 'ğŸ™ ë…¹ìŒ ì‹œì‘'}</button>

      {/* {audioURL && (
        <div style={{ marginTop: '20px' }}>
          <h3>ë…¹ìŒëœ íŒŒì¼</h3>
          <audio controls src={audioURL}></audio>
        </div>
      )} */}
    </div>
  );
};
